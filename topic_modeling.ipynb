{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import and Explore Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import from CSV\n",
    "The data_exploration notebook was used to retrieve data from Reddit using the Pushshift API via the PSAW and PRAW wrappers. That data was exported to multiple CSVs which we will use now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "load_subreddit = \"hololive\"\n",
    "load_num_posts = 20000\n",
    "load_num_days = 180\n",
    "submissions_df = pd.read_csv(f'./data/{load_subreddit}_submissions_{load_num_posts}_{load_num_days}.csv', delimiter=';', header=0)\n",
    "comments_df = pd.read_csv(f'./data/{load_subreddit}_comments_{load_num_posts}_{load_num_days}.csv', delimiter=';', header=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Data\n",
    "We take a look at what data we have imported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submissions_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ids = comments_df['link_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(post_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_ids[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_df[comments_df['link_id'] == post_ids[1]]['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean and Organize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(comment, URL_token='-URL-'):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        We clean the comment by removing comment quotes, replace URLS with tokens,\n",
    "        replace punctuation with full stops, and discard tokens that are not alphanumeric,\n",
    "        a period, or n't.\n",
    "        \n",
    "    Input:\n",
    "        comment: a raw comment text string\n",
    "        URL_token: optional parameter to set URL token, defaults to -URL-\n",
    "    \n",
    "    Output:\n",
    "        clean_comment: an array of token representing the clean comment ready to be used in a corpus \n",
    "    \"\"\"\n",
    "    if isinstance(comment, str):\n",
    "        # remove comment quotes\n",
    "        comment = re.sub(r'^>(.*?)\\n$', '', comment, flags=re.M)\n",
    "\n",
    "        # replace URLs with token\n",
    "        comment = re.sub(r'https*://\\S*', URL_token, comment)\n",
    "\n",
    "        # remove punctuation\n",
    "        comment = re.sub(r'[.,!?;]+', '.', comment)\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    comment_tokens = nltk.word_tokenize(comment)\n",
    "    clean_comment = [ch.lower() for ch in comment_tokens \n",
    "                     if ch.isalpha() # keep alphabetic words\n",
    "                     or ch == '.' # keep periods\n",
    "                     or ch =='n\\'t' # keep n't = not\n",
    "                    ]\n",
    "    return clean_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "comment_arr = []\n",
    "comments_raw = comments_df[comments_df['link_id'] == post_ids[1]]['body']\n",
    "for comment in comments_raw:\n",
    "    comment_arr.extend(clean_comment(comment))\n",
    "print(comment_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We organize the comments for each post into a dictionary to provide a clear mapping of the comment tokens (words) for each post (document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_to_comments_dict = {}\n",
    "all_comments = []\n",
    "\n",
    "for post_id in post_ids:\n",
    "    comments = []\n",
    "    # clean comments\n",
    "    comments_raw = comments_df[comments_df['link_id'] == post_id]['body']\n",
    "    for comment in comments_raw:\n",
    "        comments.extend(clean_comment(comment))\n",
    "    all_comments.extend(comments)\n",
    "    post_to_comments_dict[post_id] = comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Cleaned Data\n",
    "We examine the most frequent words which can also help us determine if more preprocessing is necessary before training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.probability import FreqDist\n",
    "fdist = FreqDist(all_comments)\n",
    "common_words = fdist.most_common(10)\n",
    "print(\"\\nCommon Words: \", common_words)\n",
    "fdist.plot(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the most common words, we can see that stopwords (the, i, to, a, it and, is, of, that) and the full stop dominate the top 10 frequent words. These will provide very little value to the topic model so we will update our clean comments function and generate a new corpora to be used. I'm also removing the URL token as this won't provide any value with regards to the topics. For now, I am avoiding stemming but may implement it in a future model to compare the improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_tokens = ['would', 'like', 'one', 'korone']\n",
    "clean_comment = [ch.lower() for ch in test_tokens \n",
    "                 if ch.isalpha() and\n",
    "                 ch.lower() not in en_stop # keep alphabetic words\n",
    "                ]\n",
    "clean_comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_comment(comment, stop_words, lemmatizer):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        We clean the comment by removing comment quotes, URLS, punctuation, \n",
    "        and discarding tokens that are not alphanumeric. We don't include words which are\n",
    "        stopwords in english\n",
    "        \n",
    "    Input:\n",
    "        comment: a raw comment text string\n",
    "        stop_words: a set of stop words to be eliminated\n",
    "        lemmatizer: a function with a method to lemmatize text\n",
    "    \n",
    "    Output:\n",
    "        clean_comment: an array of token representing the clean comment ready to be used in a corpus \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(comment, str):\n",
    "        # remove comment quotes\n",
    "        comment = re.sub(r'^>(.*?)\\n$', '', comment, flags=re.M)\n",
    "\n",
    "        # replace URLs with token\n",
    "        comment = re.sub(r'https*://\\S*', '', comment)\n",
    "\n",
    "        # remove punctuation\n",
    "        comment = re.sub(r'[.,!?;]+', '', comment)\n",
    "    else:\n",
    "        return []\n",
    "    \n",
    "    comment_tokens = nltk.word_tokenize(comment)\n",
    "    clean_comment = [ch.lower() for ch in comment_tokens \n",
    "                     if ch.isalpha() and\n",
    "                     ch.lower() not in stop_words \n",
    "                     and len(ch) > 1\n",
    "                    ]\n",
    "    clean_comment = [lemmatizer.lemmatize(word) for word in clean_comment]\n",
    "    return clean_comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer and Stop Words\n",
    "the nltk stopwords appeared to be insufficient as they did not include some of the most common terms, using gensim ones instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lemmatizer and stop words\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "wnl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "en_stop = STOPWORDS.union(set(['like', 'savevideo']))\n",
    "en_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We test the new clean_comment function to see if it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comment_arr = []\n",
    "comments_raw = comments_df[comments_df['link_id'] == post_ids[1]]['body']\n",
    "for comment in comments_raw:\n",
    "    comment_arr.extend(clean_comment(comment, en_stop, wnl))\n",
    "print(comment_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_to_comments_dict = {}\n",
    "all_comments = []\n",
    "\n",
    "for post_id in post_ids:\n",
    "    comments = []\n",
    "    # clean comments\n",
    "    comments_raw = comments_df[comments_df['link_id'] == post_id]['body']\n",
    "    for comment in comments_raw:\n",
    "        comments.extend(clean_comment(comment, en_stop, wnl))\n",
    "    all_comments.extend(comments)\n",
    "    post_to_comments_dict[post_id] = comments\n",
    "    \n",
    "len(all_comments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After removing the stopwords, full stops, and URL tokens we now have a corpora of size 1,704,363 compared to the previous size of 3,614,762.\n",
    "\n",
    "Adding lemmatization and using a slightly extended set of stopwords from gensim results in a corpora size of 1,468,682"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fdist = FreqDist(all_comments)\n",
    "common_words = fdist.most_common(10)\n",
    "print(\"\\nCommon Words: \", common_words)\n",
    "fdist.plot(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(post_to_comments_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "wordcloud = WordCloud(background_color=\"white\", width=800, height=400, colormap=\"Spectral\", max_words=500)\n",
    "wordcloud.generate_from_frequencies(fdist)\n",
    "wordcloud.to_image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the most frequent words are now like, one, would, really, stream ... perhaps this is more representative of the comments. Next we start by converting the documents into a simple vector representation using the count vectorizer. Then, we will convert a list of post comments into lists of vectors, all with length equal to the vocabulary.\n",
    "\n",
    "After updating the stopwords we have removed some of these most frequent terms, and we can see some of the most frequent words are now: stream, time, know, think, people. Not very indicative of any topics. We will evaluate this model and perhaps we can filter words out based on their POS tag for more valuable insights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of post comment lists\n",
    "post_to_comments_list = list(post_to_comments_dict.values())\n",
    "len(post_to_comments_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(post_to_comments_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "' '.join(post_to_comments_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1 - Use sklearn LDA with BoW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the library with the CountVectorizer method\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# Load the LDA model from sk-learn\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "#Convert each array of word tokens in post_to_comments_list into a string\n",
    "post_to_comments_list_str = []\n",
    "for arr in post_to_comments_list:\n",
    "    post_to_comments_list_str.append(' '.join(arr))\n",
    "\n",
    "# Initialise the count vectorizer\n",
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the processed comments\n",
    "count_data = count_vectorizer.fit_transform(post_to_comments_list_str)\n",
    "count_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word in count_data[0]:\n",
    "    print(word[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function\n",
    "def print_topics(model, count_vectorizer, n_top_words):\n",
    "    words = count_vectorizer.get_feature_names()\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([words[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tweak the two parameters below\n",
    "number_topics = 10\n",
    "number_words = 10\n",
    "# Create and fit the LDA model\n",
    "lda_model1 = LDA(n_components=number_topics, n_jobs=-1)\n",
    "lda_model1.fit(count_data)\n",
    "# Print the topics found by the LDA model\n",
    "print(\"Topics found via LDA:\")\n",
    "print_topics(lda_model1, count_vectorizer, number_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing LDA model results\n",
    "Now that we have a trained model let’s visualize the topics for interpretability. To do so, we’ll use a popular visualization package, pyLDAvis which is designed to help interactively with:\n",
    "1. Better understanding and interpreting individual topics, and\n",
    "2. Better understanding the relationships between the topics.\n",
    "    - Intertopic Distance Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyLDAvis import sklearn as sklearn_lda\n",
    "import pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LDAvis_prepared = sklearn_lda.prepare(lda_model1, count_data, count_vectorizer)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './output/topic_modeling/ldavis_prepared_model1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gensim LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have already processed our data for the first model in which we used sklearn, we will quickly examine that model and begin working with the gensim library, we will encode the corpora in 2 different ways, 1. with the BoW method, and 2. with TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_to_comments_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ipykernel deprecation warning was being triggered in every cell: https://github.com/ipython/ipykernel/issues/540\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "dictionary = gensim.corpora.Dictionary(post_to_comments_list)\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's filter out terms which appear in less than 15 documents, and terms which appear in more than 40% of documents, as well as keeping only the first 100,000 most frequent tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.4, keep_n=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Gensim LDA with BoW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BoW Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus = [dictionary.doc2bow(post) for post in post_to_comments_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_corpus[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_bow = bow_corpus[1220]\n",
    "for i in range(len(test_bow)):\n",
    "    word_num = test_bow[i][0]\n",
    "    print(f'Word {word_num}, {dictionary[word_num]}, appears {test_bow[i][1]} time(s).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=10, chunksize=100, random_state=100, workers=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyLDAvis import gensim as gensim_lda\n",
    "LDAvis_prepared = gensim_lda.prepare(lda_model, bow_corpus, dictionary)\n",
    "pyLDAvis.save_html(LDAvis_prepared, './output/topic_modeling/ldavis_prepared_model2.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pyLDAvis.display(LDAvis_prepared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Gensim LDA with TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create the tf-idf model using the bag of words corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "tfidf = models.TfidfModel(bow_corpus)\n",
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for doc in corpus_tfidf:\n",
    "    print(doc)\n",
    "    count+=1\n",
    "    if count > 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_3 = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=10, chunksize=100, random_state=100, workers=7)\n",
    "for idx, topic in lda_model_3.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 4 - Using Bigrams and POS Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(post_to_comments_list, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[post_to_comments_list], threshold=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Faster way to get a sentence clubbed as a trigram/bigram\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def functions for bigrams, trigrams\n",
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "def make_trigrams(texts):\n",
    "    return [trigram_mod[bigram_mod[doc]] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "# Form Bigrams\n",
    "data_words_bigrams = make_bigrams(post_to_comments_list)\n",
    "\n",
    "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=['parser', 'ner'])\n",
    "# Do lemmatization keeping only noun, adj, vb, adv\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "# View\n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                       id2word=id2word,\n",
    "                                       num_topics=10, \n",
    "                                       random_state=100,\n",
    "                                       chunksize=100,\n",
    "                                       passes=10,\n",
    "                                       per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics())\n",
    "doc_lda = lda_model[corpus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Assessment\n",
    "We assess the models using model perplexity and coherence. \n",
    "\n",
    "### Perplexity\n",
    "Perplexity as well is one of the intrinsic evaluation metric, and is widely used for language model evaluation. It captures how surprised a model is of new data it has not seen before, and is measured as the normalized log-likelihood of a held-out test set.\n",
    "\n",
    "However, recent studies have shown that predictive likelihood (or equivalently, perplexity) and human judgment are often not correlated, and even sometimes slightly anti-correlated. This limitation of perplexity measure served as a motivation for more work trying to model the human judgment, and thus Topic Coherence.\n",
    "\n",
    "### What is topic coherence?\n",
    "Topic Coherence measures score a single topic by measuring the degree of semantic similarity between high scoring words in the topic. These measurements help distinguish between topics that are semantically interpretable topics and topics that are artifacts of statistical inference. But …\n",
    "\n",
    "### What is coherence?\n",
    "A set of statements or facts is said to be coherent, if they support each other. Thus, a coherent fact set can be interpreted in a context that covers all or most of the facts. An example of a coherent fact set is “the game is a team sport”, “the game is played with a ball”, “the game demands great physical efforts”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate coherence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
